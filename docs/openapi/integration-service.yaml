openapi: 3.0.3
info:
  title: Integration Service API
  description: LLM provider integration proxy with circuit breaker
  version: 1.0.0

servers:
  - url: https://api.llm-governance.example.com/api/v1

tags:
  - name: Proxy
  - name: Providers

paths:
  /integrations/proxy:
    post:
      tags: [Proxy]
      summary: Proxy LLM request
      description: Proxy request to LLM provider with policy enforcement and monitoring
      security: [{bearerAuth: []}]
      requestBody:
        required: true
        content:
          application/json:
            schema: {$ref: '#/components/schemas/ProxyRequest'}
            examples:
              openai:
                summary: OpenAI GPT-4 request
                value:
                  provider: openai
                  model: gpt-4
                  messages:
                    - role: system
                      content: You are a helpful assistant
                    - role: user
                      content: Hello, how are you?
                  temperature: 0.7
                  max_tokens: 150
              anthropic:
                summary: Anthropic Claude request
                value:
                  provider: anthropic
                  model: claude-3-sonnet-20240229
                  messages:
                    - role: user
                      content: Hello, Claude!
                  max_tokens: 1024
      responses:
        '200':
          description: LLM response
          content:
            application/json:
              schema: {$ref: '#/components/schemas/ProxyResponse'}
              examples:
                openai:
                  summary: OpenAI response
                  value:
                    success: true
                    data:
                      provider: openai
                      model: gpt-4
                      content: Hello! I'm doing well, thank you for asking. How can I assist you today?
                      usage:
                        prompt_tokens: 25
                        completion_tokens: 18
                        total_tokens: 43
                      cost: 0.00129
                      latency_ms: 1250
        '422':
          description: Policy violation
        '503':
          description: Provider unavailable

  /integrations/providers:
    get:
      tags: [Providers]
      summary: List providers
      security: [{bearerAuth: []}]
      responses:
        '200':
          description: Available providers
          content:
            application/json:
              schema:
                type: object
                properties:
                  success: {type: boolean}
                  data:
                    type: object
                    properties:
                      providers:
                        type: array
                        items: {$ref: '#/components/schemas/ProviderInfo'}
              example:
                success: true
                data:
                  providers:
                    - name: openai
                      status: available
                      models: [gpt-4, gpt-4-turbo, gpt-3.5-turbo]
                    - name: anthropic
                      status: available
                      models: [claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307]

  /integrations/health:
    get:
      tags: [Providers]
      summary: Provider health check
      security: [{bearerAuth: []}]
      responses:
        '200':
          description: Health status
          content:
            application/json:
              schema:
                type: object
                properties:
                  success: {type: boolean}
                  data:
                    type: object
                    additionalProperties:
                      type: object
                      properties:
                        status: {type: string}
                        circuit_state: {type: string}
                        failure_count: {type: integer}

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer

  schemas:
    ProxyRequest:
      type: object
      required: [provider, model, messages]
      properties:
        provider:
          type: string
          enum: [openai, anthropic, google, azure, bedrock]
        model:
          type: string
        messages:
          type: array
          items:
            type: object
            properties:
              role: {type: string}
              content: {type: string}
        temperature:
          type: number
          minimum: 0
          maximum: 2
        max_tokens:
          type: integer
          minimum: 1
        top_p:
          type: number
          minimum: 0
          maximum: 1

    ProxyResponse:
      type: object
      properties:
        success: {type: boolean}
        data:
          type: object
          properties:
            provider: {type: string}
            model: {type: string}
            content: {type: string}
            usage:
              type: object
              properties:
                prompt_tokens: {type: integer}
                completion_tokens: {type: integer}
                total_tokens: {type: integer}
            cost: {type: number}
            latency_ms: {type: integer}

    ProviderInfo:
      type: object
      properties:
        name: {type: string}
        status: {type: string, enum: [available, unavailable, degraded]}
        models:
          type: array
          items: {type: string}
